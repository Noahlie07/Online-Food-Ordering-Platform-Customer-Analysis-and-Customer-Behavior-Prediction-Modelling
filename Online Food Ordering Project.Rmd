---
title: "Online Food Ordering Platform Customer Analysis and Customer Behavior Prediction Modelling"
author: Noah Alexander Lie
output: html_document
date: "2024-04-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
***

#### Purpose of This Project
This project serves as a comprehensive analysis of customer behavior based on data from an online food ordering service. This project focuses on understanding demographic trends, analyzing customer feedback, and developing a predictive model capable of forecasting customer reordering probabilities.  

The overarching goal of this project is to employ **machine learning** algorithms to determine whether a customer would likely **reorder** based on their demographic background and order details.


#### Overview of This Project
This project is structured around three core components:

1. **Demographic Analysis**: conducting basic demographic analysis to comprehend who exactly are the customers  
2. **Customer Feedback Analysis**: analyzing feedback from customers over different demographics  
3. **Predictive Modelling**: employing random forest modelling to predict customer behavior - whether they are likely to reorder or not  

***

### **1. Demographic Analysis**
<br>

First, I started off by importing and organizing the data. I imported my dataset from Kaggle using the read_csv() function. I organized the data, and also had to convert the necessary data into ordinal form for easier processing down the road. 

<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

```{r load data, results = 'hide', message=FALSE, warning=FALSE}
# RUN install.packages(c("ggplot2", "ggthemes", "tidyverse", "gridExtra", "corrplot", "randomForest", "caret", "MLmetrics"))
library(ggplot2)
library(ggthemes)
library(tidyverse)
library(readr)
library(dplyr)
library(gridExtra)
library(corrplot)
library(randomForest)
library(caret)
library(MLmetrics)

data <- read_csv("onlinefoods.csv") # load the dataset



data <- select(data, -...13) # removes a column that the original creator of the dataset says is an error
data <- rename(data, `Ordered Again` = Output) # creator of dataset mistaken the name of this column
data <- data |> mutate(`Monthly Income` = factor(`Monthly Income`, levels = c("No Income", "Below Rs.10000", "10001 to 25000", "25001 to 50000", "More than 50000"), ordered = TRUE))
data <- data |> mutate(`Family size` = factor(`Family size`, levels = c(1, 2, 3, 4, 5, 6), ordered=TRUE))
data <- data |> mutate(`Educational Qualifications` = factor(`Educational Qualifications`, levels = c("Uneducated", "School", "Graduate", "Post Graduate", "Ph.D"), ordered=TRUE))
str(data) #displays all variables in the data, along with their class

```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

##### **Pie Chart of Gender Distribution**
<br>

```{r}
# pie chart showcasing the gender demographic among the customers
gender_count <- data |> group_by(Gender) |> summarize(count = n())
gender_count <- mutate(gender_count, percentage = round(count / sum(count) * 100, 2))
pie_chart <- gender_count |> ggplot(aes(x="", y = count, fill = Gender)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar(theta = "y") + 
  theme_void() +
  labs(title = "Pie Chart with ggplot2", fill = "Gender") + 
  geom_text(aes(label = paste(count, " (", percentage, "%)", sep="")), position = position_stack(vjust = 0.5)) 
pie_chart
```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
##### **Age Distribution seperated by Gender**
<br>

```{r}
# Age Count Histogram
age_histogram <- data |> ggplot(aes(x = Age, fill = Gender)) +
  geom_histogram(position = "stack", binwidth = 2, color = "white") +
  labs(x = "Age", y = "Frequency", title = "Age Distribution of Customers") +
  scale_fill_manual(values = c("Male" = "blue", "Female" = "pink")) +
  theme_classic()
age_histogram
```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
Aside from **gender** and **age**, this dataset includes details of every customer's **marital status**, **occupation**, **monthly income level**, **family size**, **educational qualifications**.<br>  
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
```{r}
# Marital Status Demographic in Proportions
marital_status_numbers <- data |> group_by(`Marital Status`) |> 
  summarize(count = n()) |> 
  mutate(proportion = round(count / sum(count), 2)) |> arrange(desc(proportion))
bar_graph_1 <- marital_status_numbers |> 
  ggplot(aes(x = `Marital Status`, y = proportion, fill = `Marital Status`)) + 
  geom_bar(stat = "identity") +  
  geom_text(aes(label = count), vjust = 0, color = "black") + scale_y_continuous(limit = c(0, 0.7)) +
  labs(x = "Marital Status", y = "Proportion", title = "Marital Status Demographic Among Customers") +
  theme_classic()
bar_graph_1
```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
Similar method as above to obtain the count graphs of other variables:  
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
```{r, echo=FALSE}
occupation_numbers <- data |> group_by(Occupation) |> summarize(count = n()) |> mutate(proportion = round(count / sum(count), 2)) |> arrange(desc(proportion))
bar_graph_2 <- occupation_numbers |> 
  ggplot(aes(x = Occupation, y = proportion, fill = Occupation)) + 
  geom_bar(stat = "identity") +  
  geom_text(aes(label = count), vjust = 0, color = "black") + scale_y_continuous(limit = c(0, 0.7)) +
  labs(x = "Occupation", y = "Proportion", title = "Occupation Demographic Among Customers") +
  theme_classic()

# Monthly Income Demographic in Monthly Income
income_numbers <- data |> group_by(`Monthly Income`) |> summarize(count = n()) |> mutate(proportion = round(count / sum(count), 2)) 
bar_graph_3 <- income_numbers |> 
  ggplot(aes(x = `Monthly Income`, y = proportion, fill = `Monthly Income`)) + 
  geom_bar(stat = "identity") +  
  geom_text(aes(label = count), vjust = 0, color = "black") + scale_y_continuous(limit = c(0, 0.7)) +
  labs(x = "Monthly Income", y = "Proportion", title = "Monthly Income Demographic Among Customers") +
  theme_classic()

# Family Size Demographic in Family Size
family_size_numbers <- data |> group_by(`Family size`) |> summarize(count = n()) |> mutate(proportion = round(count / sum(count), 2)) 
bar_graph_4 <- family_size_numbers |> 
  ggplot(aes(x = `Family size`, y = proportion, fill = `Family size`)) + 
  geom_bar(stat = "identity") +  
  geom_text(aes(label = count), vjust = 0, color = "black") + scale_y_continuous(limit = c(0, 0.7)) +
  labs(x = "Family Size", y = "Proportion", title = "Family Size Demographic Among Customers") +
  theme_classic()


# Educational Qualifications Demographic in Educational Qualifications
educational_qualifications_numbers <- data |> group_by(`Educational Qualifications`) |> summarize(count = n()) |> mutate(proportion = round(count / sum(count), 2)) 
bar_graph_5 <- educational_qualifications_numbers |> 
  ggplot(aes(x = `Educational Qualifications`, y = proportion, fill = `Educational Qualifications`)) + 
  geom_bar(stat = "identity") +  
  geom_text(aes(label = count), vjust = 0, color = "black") + scale_y_continuous(limit = c(0, 0.7)) +
  labs(x = "Educational Qualifications", y = "Proportion", title = "Educational Qualification Demographic Among Customers") +
  theme_classic()

grid.arrange(bar_graph_2, bar_graph_3, bar_graph_4, bar_graph_5, ncol = 2)
```

<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
From these count graphs, conclusions can be drawn that:

* Most of the customers are Single
* The service is  popular among young adults, particularly students, who may prioritize convenience.
* The customer base is diverse in terms of monthly income
* The service seems to appeal more to individuals and small families, potentially due to lifestyle and convenience factors.
* The educational level of the customer base skews higher, with a significant representation of graduates and postgraduates.
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

##### **Violin Plot of Age Distribution Vs Monthly Income**
<br>

```{r}
#Violin Plot of Age Vs Monthly Income
violin_plot <- data |> group_by(Gender) |> ggplot(aes(x = `Monthly Income`, y = Age, fill = Gender)) +
  geom_violin() + 
  labs(x = "Monthly Income", y = "Age", title = "Age Distribution by Monthly Income") +
  scale_fill_manual(values = c("Male" = "blue", "Female" = "pink")) 
violin_plot
```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
From the violin plot above, we can infer that:

* The higher the income bracket, the older the age range and the more the plot skews towards an older age range
* Dominant age range around ~25  
**Make note of outliers present**
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

##### **Correlation between Customer Demographic**
<br>

From the correlation matrices below, although there is some correlation between variables, correlation is **minimal**. This is seen by 0.17 being the highest correlation coefficient among variables.
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
```{r}
# Correlation Matrix Among Numeric Data
color <- colorRampPalette(c("white", "red"))(100)
correlation_matrix_graph <- data |> mutate(`Family size` = as.numeric(`Family size`)) |> 
  select(Age, `Family size`, latitude, longitude) |> 
  cor() |> corrplot(method = "color", , tl.col = "black", tl.srt = 45, 
                    addCoef.col = "black", col = color) 
correlation_matrix_graph


#Correlation Matrix Among Ordinal Data
correlation_matrix_graph2 <- data |>  mutate(`Family size` = as.numeric(`Family size`), `Monthly Income` = as.numeric(`Monthly Income`), 
  `Educational Qualifications` = as.numeric(`Educational Qualifications`)) |>
  select(`Family size`, `Monthly Income`, `Educational Qualifications`) |> cor(method = "kendall") |> 
  corrplot(method = "color", tl.col = "black", tl.cex = 0.8, tl.srt = 45, 
           addCoef.col = "black", col = color)
```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

***

### **2. Customer Feedback Analysis**
<br>

```{r}
# Basic Feedback Analysis
feedbacks <- data |> group_by(Feedback) |> summarize(count = n()) |> mutate(percentage = round(count/sum(count) * 100, 2))
feedback_bar_graph <- feedbacks |> ggplot(aes(x = Feedback, y = count, fill = Feedback)) +
  geom_bar(stat = "identity") +  
  labs(x = "Feedback", y = "Frequency") + scale_y_continuous(limit = c(0, sum(feedbacks$count))) + 
  geom_text(aes(label = paste(percentage, "%", sep="")), vjust = -1) + 
  scale_fill_manual(values = c("Positive" = "green", "Negative" = "red")) +
  theme_classic()
feedback_bar_graph

# Feedback by Monthly Income
feedback_by_monthlyincome_graph <- data |> group_by(Feedback) |> ggplot(aes(x = `Monthly Income`, fill = Feedback)) +
  geom_bar(position = "dodge") +
  labs(x = "Monthly Income", y = "Number of Feedbacks", title = "Monthly Income & Feedback Analysis") + 
  scale_y_continuous(limit = c(0, sum(feedbacks$count) / 2)) +
  scale_fill_manual(values = c("Positive" = "green", "Negative" = "red")) +
  theme_classic()
feedback_by_monthlyincome_graph
```

Several conclusions drawn from the graph above:  

1.	Customers with "No Income" provided the highest positive to negative ratio
2.	Customers with ‘Below 10000’ income show the most even feedback, with the frequency of positive and negative feedbacks being very close
3.	The consistency of negative feedback across income brackets suggests that there may be common issues faced by customers leading to dissatisfaction, irrespective of their income level.

<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

##### Feedback Vs Ordered-Again Ratio

<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

```{r}
# Feedback Vs Ordered-Again Ratio
data_used <- data |> group_by(Feedback, `Ordered Again`) |> summarize(count = n(), .groups = 'drop') |> 
  group_by(Feedback) |> mutate(percentage = round((count / sum(count)) * 100, 1))
data_used <- data_used |> arrange(Feedback, desc(`Ordered Again`)) |> group_by(Feedback) |> mutate(label_position = cumsum(count) - (0.5* count))
feedback_v_orderedagain <- data_used |> ggplot(aes(x = Feedback, y = count, fill = `Ordered Again`)) + 
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = paste(percentage, "%"), y = label_position), vjust = 0.5) +
  labs(x = "Feedback", y = "Frequency", title = "Feedback - Order Again Relationship") + 
  scale_fill_manual(values = c("Yes" = "green", "No" = "red")) +
  theme_classic()
  
feedback_v_orderedagain
```

Unsurprisingly, we see that when feedbacks are positive, customers are more likely to order again. The opposite case is also true.
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

##### Ordering Behavior by Monthly Income and Age

<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

```{r}
#Ordering Behavior by Monthly Income and Age
monthlyincome_age_orderingbehavior <- data |> ggplot(aes(x = Age, y = `Monthly Income`, fill = `Ordered Again`)) +
  geom_boxplot() +
  scale_fill_manual(values = c("Yes" = "blue", "No" = "red")) +
  labs(x = "Age", y = "Monthly Income", title = "Order-Again Behavior by Monthly Income and Age", fill = "Ordered Again")
monthlyincome_age_orderingbehavior
```

Observations:  

* The age distribution of those who ordered again and those who didn’t are particularly different for Income groups “Below Rs.10000”, “10001 to 25000” and “25001 to 50000”, suggesting that age plays a big factor
* The age distribution of those who ordered again and those who didn’t for the other income groups (“No Income” and “More than 50000” are overlapping, suggesting that age does not play a huge factor in the decision within these income groups

<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>

***

### **3. Predictive Modelling**
<br>

First, I tidied up my data by converting all nominal values to equivalent integers. Since my dataset contained a lot of ordinal and nominal data, I chose to employ random forest modelling as basis for my predictive model.      
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
```{r}
data <- data |> mutate(`Marital Status` = as.integer(factor(`Marital Status`, levels = c("Prefer not to say", "Single", "Married"))),
                       Gender = as.integer(factor(Gender, levels = c("Male", "Female"))), Occupation = as.integer(factor(Occupation, 
                       levels = c("Employee", "House wife", "Self Employeed", "Student"))), 
                       Feedback = as.integer(factor(Feedback, levels = c("Negative", "Positive")))- 1)
data <- data |> select(-latitude, -longitude, -`Pin code`) 
# removes unnecessary variables - we cannot ascertain the correlation between the location of the customer and whether they will order again, 
# as the dataset does not give us the location of the customer RELATIVE to the restaurant location (This is one flaw of the dataset)
data <- data |> rename(MaritalStatus = `Marital Status`, MonthlyIncome = `Monthly Income`, EducationalQualifications = `Educational Qualifications`, FamilySize = `Family size`)
data$`Ordered Again` <- factor(data$`Ordered Again`, levels = c("Yes", "No"))
#This line of code above is very important - 
# Make note that if the customer did not order again, the equivalent nominal value is 0. If they did order again, the equivalent nominal value is 1.
str(data)
```
Notice that I have dropped the location of the customers from the dataset I would be using. The reason for this is because the location of the customers were all relatively similar. Additionally, there was no information as to how close their locations were relative to the restaurant, therefore it is futile to take their locations into consideration. 

```{r}
set.seed(2024) # For reproducibility of results
split_data <- createDataPartition(y=1:nrow(data), p = 0.7, list = FALSE) # splits our existing dataset 7:3
train_set <- data[split_data, ] # 70% of our data is used for training our model
test_set <- data[-split_data, ] # 30% of our data is used for testing our model
```

```{r}
randomforest_model <- randomForest(`Ordered Again`~ ., data = train_set, ntree = 100)
print(randomforest_model)

predictions <- predict(randomforest_model, test_set) #generate predictions with our test set

cm_yes <- confusionMatrix(predictions, test_set$`Ordered Again`, positive = "Yes") # positive class is Yes
print(cm_yes)

#Extract accuracy, sensitivity, and specificity from the matrix
accuracy_yes <- cm_yes$overall[["Accuracy"]]
sensitivity_yes <- cm_yes$byClass['Sensitivity']
specificity_yes <- cm_yes$byClass['Specificity']

#Generate f1
f1_score <- F_meas(predictions, test_set$`Ordered Again`, positive = "Yes")

summary_table <- pivot_longer(data.frame(`Overall Accuracy` = accuracy_yes, Sensitivity = sensitivity_yes, 
                                         Specificity = specificity_yes, `F1 Score` = f1_score), cols = everything())
print(summary_table)
summary_graph <- summary_table |> ggplot(aes(x = name, y = value)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = 0.5) + 
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "Metrics", title = "Random Forest Model")
print(summary_graph)
```

**The graph below tells us which variables are most important for determining whether a customer would likely reorder again. Unsurprisingly, the customer's feedback is the most important variable in determining whether a reorder is likely in the future.**
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
```{r}
varImpPlot(randomforest_model, main = paste("Variable Importance in Order: "))
```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
Out of curiosity, I created the average customer and instructed the model to evaluate whether the customer would likely reorder.
```{r}
# Creating the average customer and predicting whether they will reorder
average_customer <- data.frame(
  Age = median(data$Age),
  MaritalStatus = as.integer(median(as.integer(data$MaritalStatus))),
  Gender = as.integer(median(as.integer(data$Gender))),
  Occupation = as.integer(median(as.integer(data$Occupation))),
  Feedback = as.integer(median(as.integer(data$Feedback))),
  MonthlyIncome = as.integer(median(as.integer(data$MonthlyIncome))),
  EducationalQualifications = as.integer(median(as.integer(data$EducationalQualifications))),
  FamilySize = as.integer(median(as.integer(data$FamilySize)))
)
print(average_customer)
# Predicting with the random forest model
average_customer_prediction <- predict(randomforest_model, newdata = average_customer)
print(average_customer_prediction)
```
<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
Despite successfully creating a prediction model, I was unsatisfied with the **specificity** of the model. Therefore, I tried to improve the model by setting the model on emphasizing its specificity. I also performed a standard **5 fold cross-validation** of my random forest model to better evaluate my model and also reduce any likelihood of over-fitting.  

#### **Improving The Model**

<div style="margin-top: 1.5em; margin-bottom: 1.5em;"> <!-- Adds space around the code chunk -->
</div>
```{r}
### Improving Accuracy, Sensitivity and Specificity of the model

## Method Cross-Validation & Emphasizing on Optimizing Specificity
train_control <- trainControl(method = "cv", number = 5, summaryFunction = twoClassSummary) # Standard 5-fold cross valdiation

# Train the Random Forest model with cross-validation this time
randomforest_model_cv <- train(`Ordered Again` ~ ., data = train_set, method = "rf", trControl = train_control, metric = "Spec", tuneLength = 20)
# now using train() instead of randomForest() because I find that this function offers greater flexibility for parameter tuning
print(randomforest_model_cv)


predictions_cv <- predict(randomforest_model_cv, newdata = test_set)

# Generate Confusion Matrix
cm_cv <- confusionMatrix(predictions_cv, test_set$`Ordered Again`, positive = "Yes")
print(cm_cv)

accuracy_v2 <- cm_cv$overall[["Accuracy"]]
sensitivity_v2 <- cm_cv$byClass['Sensitivity']
specificity_v2 <- cm_cv$byClass['Specificity']

#Generate f1
f1_score_v2 <- F_meas(predictions_cv, test_set$`Ordered Again`, positive = "Yes")

summary_table_v2 <- pivot_longer(data.frame(`Overall Accuracy` = accuracy_v2, Sensitivity = sensitivity_v2, 
                                            Specificity = specificity_v2, `F1 Score` = f1_score_v2), cols = everything())
print(summary_table_v2)
summary_graph_v2 <- summary_table_v2 |> ggplot(aes(x = name, y = value)) + geom_bar(stat = "identity", fill = "red", alpha = 0.5) + 
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "Metrics", title = "Improved Model")
print(summary_graph_v2)
```

```{r}
summary_table$Model <- "Original"
summary_table_v2$Model <- "Improved"

# Combine summary tables
combined_summary <- rbind(summary_table, summary_table_v2) |> mutate(Model = factor(Model, levels = c("Original", "Improved")))

# Plot combined summary tables
combined_summary_plot <- ggplot(combined_summary, aes(x = name, y = value, fill = Model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.5), alpha = 0.5) +
  scale_fill_manual(values = c("Original" = "blue", "Improved" = "red")) +
  labs(title = "Comparison of Original Vs Improved", x = "Metric", y = "Value") +
  theme(legend.position = "top") +
  theme_classic() 


# Print the combined plot
print(combined_summary_plot)
```
Through my calibration, I was able to increase the specificity of my model. However, it is still only around **58%**. This brings me to the limitations of my project.

***
#### **Limitations**
<br>

This project contains several limitations:

1. **Limited Observations** - This dataset only has around 400 observations. This makes it difficult to train my prediction model, as I have less training data to work with, thereby resulting in a less accurate product.
2. **Limited Variables** - This dataset provided limited variables on each observation. Aside from information on whether the customer ordered again and their feedback upon ordering, the dataset did not include other order details which could have lended excellent insight into each order. For instance, details on the time of order, delivery time, and foods ordered, if fed to the predictive model, could all have been excellent indicators on whether a customer would reorder in the future.
3. **Concentrated cultural demographic** - This dataset was derived from an online food ordering service in India. All of its customers have their location in India, and therefore it can be inferred that most of the customer base are Indian. Therefore, it is worth keeping in mind that results could be different for other cultural demographics. 

***
## Thank you for looking into my project. Feel free to leave a comment at 
#### Contact Info: noahalexanderlie@gmail.com
